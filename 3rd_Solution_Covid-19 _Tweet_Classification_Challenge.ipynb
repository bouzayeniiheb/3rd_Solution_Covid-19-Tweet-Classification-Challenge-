{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNuzgGwUYBnUZyC+MvPX8qR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bouzayeniiheb/3rd_Solution_Covid-19-Tweet-Classification-Challenge-/blob/master/3rd_Solution_Covid-19%20_Tweet_Classification_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVtUWWpsQfOo",
        "colab_type": "text"
      },
      "source": [
        "### **COVID-19 Tweet Classification Challenge by #ZindiWeekendz**\n",
        "\n",
        "Here is my solution for this hackhaton,\n",
        "I used two models using fastai with Roberta Large.\n",
        "\n",
        "I wrote all my code in this notebook with clear comments.\n",
        "\n",
        "P.S:\n",
        "\n",
        "*   Please run this code in google colab to get the same results.\n",
        "\n",
        "*   If you have a problem in cuda memory, please run the second model in another notebook using a second gmail account.Don't forget to import the libraries.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwQ01VaQj6MN",
        "colab_type": "text"
      },
      "source": [
        "Before starting the implementation, you will need to install the fastai and transformers libraries. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXUe7mqMcazp",
        "colab_type": "code",
        "outputId": "cf9aa8ce-fbf6-4ff6-860e-a31162aca1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "!pip install fastai"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
            "Requirement already satisfied: torch_nightly in /usr/local/lib/python3.6/dist-packages (1.2.0.dev20190805+cu92)\n",
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.61)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.5.0+cu101)\n",
            "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.6.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.18.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.1)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.2.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai) (0.16.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.6.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (46.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rWRBpFoxgnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "bb4ab9a1-64fa-459e-8618-411450be89f3"
      },
      "source": [
        "! pip install pytorch-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.18.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.0.43)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.13.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (0.1.86)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.5.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: botocore<1.17.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.16.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch-transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.4->boto3->pytorch-transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0wYQAU80m0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "a0f20dbc-b6ab-4589-e15f-d39d73c6258d"
      },
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install simpletransformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: transformers in /usr/local/lib/python3.6/dist-packages (2.9.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: simpletransformers in /usr/local/lib/python3.6/dist-packages (0.28.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (4.41.1)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (0.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.18.4)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.0.3)\n",
            "Requirement already satisfied: transformers>=2.9.0 in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (0.22.2.post1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->simpletransformers) (2.3.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardx->simpletransformers) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->simpletransformers) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->simpletransformers) (2.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.0->simpletransformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.0->simpletransformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.0->simpletransformers) (0.1.86)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.9.0->simpletransformers) (0.0.43)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2020.4.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->simpletransformers) (0.14.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->simpletransformers) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardx->simpletransformers) (46.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.9.0->simpletransformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze0fxELN09BB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7906702a-d634-42f6-9cb5-f4162d21da58"
      },
      "source": [
        "pip install Pillow"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6--Ht4VkYTw",
        "colab_type": "text"
      },
      "source": [
        "Import the necessary librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOknqbXOhIV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8rRpRW40twI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b11fd77-2620-444b-be5d-36900f5328c1"
      },
      "source": [
        "entrypoints = torch.hub.list('pytorch/vision:v0.4.0', force_reload=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.4.0.zip\" to /root/.cache/torch/hub/v0.4.0.zip\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXiCwk8JytCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import gc\n",
        "from scipy.special import softmax\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "import sklearn\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import *\n",
        "import re\n",
        "import random\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFhyXR6akjou",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "The current versions of the fastai and transformers libraries are respectively 1.0.61 and 2.9.0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7diribSyhLDD",
        "colab_type": "code",
        "outputId": "9a846cc5-5c29-4ff5-e585-600227e4d70b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\n",
        "\n",
        "import fastai\n",
        "import transformers\n",
        "print('fastai version :', fastai.__version__)\n",
        "print('transformers version :', transformers.__version__)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version : 1.0.61\n",
            "transformers version : 2.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsZuDBUWkueR",
        "colab_type": "text"
      },
      "source": [
        "Read the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geYDQrjteoZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_PATH = '/content/updated_train.csv'\n",
        "TEST_PATH = '/content/updated_test.csv'\n",
        "SAMPLE_SUB_PATH = '/content/updated_ss.csv'\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "sample_sub = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "ID_COL, TARGET_COL = sample_sub.columns.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKnja4t9kyas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "daaa962d-e9e6-4c1f-b860-d377ac0a78a5"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>The bitcoin halving is cancelled due to</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>MercyOfAllah In good times wrapped in its gran...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>266 Days No Digital India No Murder of e learn...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>India is likely to run out of the remaining RN...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>In these tough times the best way to grow is t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID                                               text  target\n",
              "0  train_0            The bitcoin halving is cancelled due to       1\n",
              "1  train_1  MercyOfAllah In good times wrapped in its gran...       0\n",
              "2  train_2  266 Days No Digital India No Murder of e learn...       1\n",
              "3  train_3  India is likely to run out of the remaining RN...       1\n",
              "4  train_4  In these tough times the best way to grow is t...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTBzQmgAkydj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "7804685f-782f-4671-98ff-da18ec72ca22"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5287.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.480613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.499671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            target\n",
              "count  5287.000000\n",
              "mean      0.480613\n",
              "std       0.499671\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%       0.000000\n",
              "75%       1.000000\n",
              "max       1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBNVjNKzleVQ",
        "colab_type": "text"
      },
      "source": [
        "As we see here the train data set is well balanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYISW8ctk40N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "479ac1c7-d851-46ef-f2c7-0bcc1deaa8e4"
      },
      "source": [
        "train['target'].value_counts()"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2746\n",
              "1    2541\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVAW_ysKlu0r",
        "colab_type": "text"
      },
      "source": [
        "Check missing values in the train and test datafames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cWtqNQOlmGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4978ae68-78fe-4ec9-ed99-0d56d932f79a"
      },
      "source": [
        "train['target'].isnull().sum()"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNd_4Uc5mFX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6db0de2-5ff8-433c-8efd-5e9d8dcaa31f"
      },
      "source": [
        "train['text'].isnull().sum()"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf8_k8c3l71t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92ade622-c9c0-4255-f18c-36f67b59882d"
      },
      "source": [
        "test['text'].isnull().sum()"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GotyEnh8mTyE",
        "colab_type": "text"
      },
      "source": [
        "### **Roberta Large Model1:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azm1rganeVOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_CLASSES = {\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ukFkmd1evki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n",
        "model_type = 'roberta'\n",
        "pretrained_model_name = 'roberta-large'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmXN09opezqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZVLXc6dmltH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Function to set the seed for generating random numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VcWuuqHe6Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmGDi6AffFT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPyVIAu0nIMN",
        "colab_type": "text"
      },
      "source": [
        "**Data pre-processing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko_HAwh1nazD",
        "colab_type": "text"
      },
      "source": [
        "to match pre-training, we have to format the model input sequence in a specific format. To do so, you have to first **tokenize** and then **numericalize** the texts correctly. The difficulty here is that each pre-trained model, that we will fine-tune, requires exactly the same specific pre-process - **tokenization** & **numericalization **- than the pre-process used during the pre-train part. Fortunately, the **tokenizer class** from transformers provides the correct pre-process tools that correspond to each pre-trained model.\n",
        "\n",
        "In the fastai library, data pre-processing is done automatically during the creation of the DataBunch. As you will see in the DataBunch implementation, the tokenizer and numericalizer are passed in the processor argument under the following format :\n",
        "\n",
        "processor = [TokenizeProcessor(tokenizer=tokenizer,...), NumericalizeProcessor(vocab=vocab,...)]\n",
        "\n",
        "Let's first analyse how we can integrate the transformers tokenizer within the TokenizeProcessor function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0skpvscn-MS",
        "colab_type": "text"
      },
      "source": [
        "*Custom Tokenizer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m4X0uM6oDME",
        "colab_type": "text"
      },
      "source": [
        "This part can be a little bit confusing because a lot of classes are wrapped in each other and with similar names. To resume, if we look attentively at the fastai implementation, we notice that :\n",
        "\n",
        "\n",
        "1.   The TokenizeProcessor object takes as tokenizer argument a Tokenizer object.\n",
        "2.  The Tokenizer object takes as tok_func argument a BaseTokenizer object.\n",
        "3. The BaseTokenizer object implement the function tokenizer(t:str) → List[str] that take a text t and returns the list of its tokens.\n",
        "\n",
        "Therefore, we can simply create a new class TransformersBaseTokenizer that inherits from BaseTokenizer and overwrite a new tokenizer function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoJ44ioIfHGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "            tokens = [CLS] + tokens + [SEP]\n",
        "        \n",
        "        return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYwnsf27fMr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4VxyNjKpKpq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*Custom Numericalizer:*\n",
        "\n",
        "In fastai, NumericalizeProcessor object takes as vocab argument a Vocab object. From this analyse, I suggest one way to adapt the fastai numericalizer:\n",
        "\n",
        "\n",
        "1.   Create a new class TransformersVocab that inherits from Vocab and overwrite numericalize and textify functions.\n",
        "\n",
        "this solution runs for each model type. It consists of using the functions convert_tokens_to_ids and convert_ids_to_tokens in respectively numericalize and textify.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xllPEjQsfTSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n",
        "    \n",
        "    def __getstate__(self):\n",
        "        return {'itos':self.itos, 'tokenizer':self.tokenizer}\n",
        "\n",
        "    def __setstate__(self, state:dict):\n",
        "        self.itos = state['itos']\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        self.stoi = collections.defaultdict(int,{v:k for k,v in enumerate(self.itos)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDcEwxiSqfkU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "NB: The functions __gestate__ and __setstate__ allow the functions export and load_learner to work correctly with TransformersVocab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btJvTIRcqjfG",
        "colab_type": "text"
      },
      "source": [
        "*Setting up the Databunch:*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWiRBXF7q1HD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "There is multiple ways to create a DataBunch, in my implementation, I use the data block API, which gives more flexibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU47M4XUf5Fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot5iKn7R2IEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgSEfycAgFuK",
        "colab_type": "code",
        "outputId": "5cbc376e-dc1b-4a72-fc72-4d23257415d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "databunch = (TextList.from_df(train, cols='text', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'target')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-qTOCixrBt7",
        "colab_type": "text"
      },
      "source": [
        "*Custom model:*\n",
        "\n",
        "every model's forward method always outputs a tuple with various elements depending on the model and the configuration parameters. In our case, we are interested to access only to the logits.  One way to access them is to create a custom model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S5Aqx82gJzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomTransformerModel(nn.Module):\n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \n",
        "        # attention_mask\n",
        "        # Mask to avoid performing attention on padding token indices.\n",
        "        # Mask values selected in ``[0, 1]``:\n",
        "        # ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n",
        "        attention_mask = (input_ids!=pad_idx).type(input_ids.type()) \n",
        "        \n",
        "        logits = self.transformer(input_ids,\n",
        "                                  attention_mask = attention_mask)[0]   \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDMAJ25DrQZD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "To make our transformers adapted to multiclass classification, before loading the pre-trained model, we need to precise the number of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3RYWEmsiFYw",
        "colab_type": "code",
        "outputId": "8f4a79b0-85ef-4014-daab-d648cb45b436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "config = config_class.from_pretrained(pretrained_model_name)\n",
        "config.num_labels = 2\n",
        "config.use_bfloat16 = use_fp16\n",
        "print(config)"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX8Vwzt1iSmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_model = model_class.from_pretrained(pretrained_model_name, config = config)\n",
        "\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC_C5rVcrUak",
        "colab_type": "text"
      },
      "source": [
        "*Learner : Custom Optimizer / Custom Metric:*\n",
        "\n",
        "In pytorch-transformers, HuggingFace had implemented two specific optimizers  -  BertAdam and OpenAIAdam  -  that have been replaced by a single AdamW optimizer. This optimizer matches Pytorch Adam optimizer Api, therefore, it becomes straightforward to integrate it within fastai. It is worth noting that for reproducing BertAdam specific behavior, you have to set correct_bias = False.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVw0X_lBiY4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.callbacks import *\n",
        "from transformers import AdamW\n",
        "from functools import partial\n",
        "\n",
        "CustomAdamW = partial(AdamW, correct_bias=False)\n",
        "\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = CustomAdamW, \n",
        "                  metrics=[accuracy, error_rate])\n",
        "\n",
        "# Show graph of learner stats and metrics after each epoch.\n",
        "learner.callbacks.append(ShowGraph(learner))\n",
        "\n",
        "# Put learn in FP16 precision mode. --> Seems to not working\n",
        "if use_fp16: learner = learner.to_fp16()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1lK17xcr8c7",
        "colab_type": "text"
      },
      "source": [
        "I can decide to divide the model in 14 blocks :\n",
        "\n",
        "\n",
        "*   1 Embedding\n",
        "*   12 transformer\n",
        "*   1 classifier\n",
        "\n",
        "In this case, we can split our model in this way :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOcIEye_8xqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_layers = [learner.model.transformer.roberta.embeddings,\n",
        "              learner.model.transformer.roberta.encoder.layer[0],\n",
        "              learner.model.transformer.roberta.encoder.layer[1],\n",
        "              learner.model.transformer.roberta.encoder.layer[2],\n",
        "              learner.model.transformer.roberta.encoder.layer[3],\n",
        "              learner.model.transformer.roberta.encoder.layer[4],\n",
        "              learner.model.transformer.roberta.encoder.layer[5],\n",
        "              learner.model.transformer.roberta.encoder.layer[6],\n",
        "              learner.model.transformer.roberta.encoder.layer[7],\n",
        "              learner.model.transformer.roberta.encoder.layer[8],\n",
        "              learner.model.transformer.roberta.encoder.layer[9],\n",
        "              learner.model.transformer.roberta.encoder.layer[10],\n",
        "              learner.model.transformer.roberta.encoder.layer[11],\n",
        "              learner.model.transformer.roberta.pooler]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZVIVpoHsJM7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Check groups :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmClenCRihVY",
        "colab_type": "code",
        "outputId": "73ab2d77-f620-4835-f39c-a288f4c4e521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learner.split(list_layers)\n",
        "num_groups = len(learner.layer_groups)\n",
        "print('Learner split in',num_groups,'groups')\n",
        "print(learner.layer_groups)"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learner split in 14 groups\n",
            "[Sequential(\n",
            "  (0): Embedding(50265, 1024, padding_idx=1)\n",
            "  (1): Embedding(514, 1024, padding_idx=1)\n",
            "  (2): Embedding(1, 1024)\n",
            "  (3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (4): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (6): Dropout(p=0.1, inplace=False)\n",
            "  (7): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (10): Dropout(p=0.1, inplace=False)\n",
            "  (11): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (12): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (13): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (14): Dropout(p=0.1, inplace=False)\n",
            "  (15): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (16): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (17): Dropout(p=0.1, inplace=False)\n",
            "  (18): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (19): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (20): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (21): Dropout(p=0.1, inplace=False)\n",
            "  (22): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (23): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (24): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (25): Dropout(p=0.1, inplace=False)\n",
            "  (26): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (27): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (28): Dropout(p=0.1, inplace=False)\n",
            "  (29): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (30): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (31): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (32): Dropout(p=0.1, inplace=False)\n",
            "  (33): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (34): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (35): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (36): Dropout(p=0.1, inplace=False)\n",
            "  (37): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (38): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (39): Dropout(p=0.1, inplace=False)\n",
            "  (40): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (41): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (42): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (43): Dropout(p=0.1, inplace=False)\n",
            "  (44): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (45): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (46): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (47): Dropout(p=0.1, inplace=False)\n",
            "  (48): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (49): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (50): Dropout(p=0.1, inplace=False)\n",
            "  (51): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (52): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (53): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (54): Dropout(p=0.1, inplace=False)\n",
            "  (55): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (56): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (57): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (58): Dropout(p=0.1, inplace=False)\n",
            "  (59): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (60): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (61): Dropout(p=0.1, inplace=False)\n",
            "  (62): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (63): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (64): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (65): Dropout(p=0.1, inplace=False)\n",
            "  (66): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (67): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (68): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (69): Dropout(p=0.1, inplace=False)\n",
            "  (70): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (71): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (72): Dropout(p=0.1, inplace=False)\n",
            "  (73): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (74): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (75): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (76): Dropout(p=0.1, inplace=False)\n",
            "  (77): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (78): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (79): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (80): Dropout(p=0.1, inplace=False)\n",
            "  (81): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (82): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (83): Dropout(p=0.1, inplace=False)\n",
            "  (84): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (85): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (86): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (87): Dropout(p=0.1, inplace=False)\n",
            "  (88): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (89): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (90): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (91): Dropout(p=0.1, inplace=False)\n",
            "  (92): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (93): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (94): Dropout(p=0.1, inplace=False)\n",
            "  (95): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (96): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (97): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (98): Dropout(p=0.1, inplace=False)\n",
            "  (99): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (100): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (101): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (102): Dropout(p=0.1, inplace=False)\n",
            "  (103): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (104): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (105): Dropout(p=0.1, inplace=False)\n",
            "  (106): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (107): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (108): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (109): Dropout(p=0.1, inplace=False)\n",
            "  (110): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (111): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (112): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (113): Dropout(p=0.1, inplace=False)\n",
            "  (114): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (115): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (116): Dropout(p=0.1, inplace=False)\n",
            "  (117): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (118): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (119): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (120): Dropout(p=0.1, inplace=False)\n",
            "  (121): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (122): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (123): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (124): Dropout(p=0.1, inplace=False)\n",
            "  (125): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (126): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (127): Dropout(p=0.1, inplace=False)\n",
            "  (128): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (129): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (130): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (131): Dropout(p=0.1, inplace=False)\n",
            "  (132): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (133): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (134): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (135): Dropout(p=0.1, inplace=False)\n",
            "  (136): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (137): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (138): Dropout(p=0.1, inplace=False)\n",
            "  (139): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "  (140): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (141): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (142): Dropout(p=0.1, inplace=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (1): Tanh()\n",
            "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (3): Dropout(p=0.1, inplace=False)\n",
            "  (4): Linear(in_features=1024, out_features=2, bias=True)\n",
            ")]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSeLZyW8sSLs",
        "colab_type": "text"
      },
      "source": [
        "*Train*\n",
        "\n",
        "Now we can finally use all the fastai build-in features to train our model. Like the ULMFiT method, we will use Slanted Triangular Learning Rates, Discriminate Learning Rate and gradually unfreeze the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VG21nPlijWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('untrain')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMJQLXQil2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('untrain');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3a5pkQ1sbvC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Therefore, we first freeze all the groups but the classifier with :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_U1YesPinjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s07bODgXsdiE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "We check which layer are trainable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mJVpazaio-X",
        "colab_type": "code",
        "outputId": "f9f77917-2b5e-41f8-9e62-38b8334fa76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "learner.summary()"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTransformerModel\n",
              "======================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "======================================================================\n",
              "Embedding            [85, 1024]           51,471,360 False     \n",
              "______________________________________________________________________\n",
              "Embedding            [85, 1024]           526,336    False     \n",
              "______________________________________________________________________\n",
              "Embedding            [85, 1024]           1,024      False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "Dropout              [16, 85, 85]         0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           1,049,600  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 4096]           4,198,400  False     \n",
              "______________________________________________________________________\n",
              "Linear               [85, 1024]           4,195,328  False     \n",
              "______________________________________________________________________\n",
              "LayerNorm            [85, 1024]           2,048      False     \n",
              "______________________________________________________________________\n",
              "Dropout              [85, 1024]           0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [1024]               1,049,600  True      \n",
              "______________________________________________________________________\n",
              "Tanh                 [1024]               0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [1024]               1,049,600  True      \n",
              "______________________________________________________________________\n",
              "Dropout              [1024]               0          False     \n",
              "______________________________________________________________________\n",
              "Linear               [2]                  2,050      True      \n",
              "______________________________________________________________________\n",
              "\n",
              "Total params: 356,411,394\n",
              "Total trainable params: 2,101,250\n",
              "Total non-trainable params: 354,310,144\n",
              "Optimized with 'transformers.optimization.AdamW', correct_bias=False\n",
              "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
              "Loss function : FlattenedLoss\n",
              "======================================================================\n",
              "Callbacks functions applied \n",
              "    ShowGraph"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiO7U-9bsmiD",
        "colab_type": "text"
      },
      "source": [
        "For Slanted Triangular Learning Rates you have to use the function one_cycle.\n",
        "\n",
        "To use our one_cycle we will need an optimum learning rate. We can find this learning rate by using a learning rate finder which can be called by using lr_find."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvKjmHHHiqNl",
        "colab_type": "code",
        "outputId": "58932ad3-6ed3-4095-ad70-bd7eb0e86a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='71' class='' max='297' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      23.91% [71/297 00:21<01:08 2.6173]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZbDslVuivVY",
        "colab_type": "code",
        "outputId": "65274c30-2d9d-42a5-b548-f21e249a2320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "learner.recorder.plot(skip_end=10,suggestion=True)"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min numerical gradient: 6.31E-07\n",
            "Min loss divided by 10: 9.12E-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKEk8GigsznI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "I will pick a value a bit before the minimum, where the loss still improves. Here 2x10^-3 seems to be a good value.\n",
        "\n",
        "Next I will use fit_one_cycle with the chosen learning rate as the maximum learning rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ATEejkiyDf",
        "colab_type": "code",
        "outputId": "61828900-510f-4f88-d19b-b3ca18ec05d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "learner.fit_one_cycle(1,max_lr=2e-03,moms=(0.8,0.7))"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.416115</td>\n",
              "      <td>0.328555</td>\n",
              "      <td>0.856061</td>\n",
              "      <td>0.143939</td>\n",
              "      <td>01:12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx0UQjlEi0zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('first_cycle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_FhDMIwi49I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "seed_all(seed)\n",
        "learner.load('first_cycle');\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9i765bMs6Rl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "I then unfreeze the second group of layers and repeat the operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk-N7kKhi6rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6peyIp-i8O3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iFvdbVEs9lq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Note here that i use slice to create separate learning rate for each group.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en-_HUCoi91P",
        "colab_type": "code",
        "outputId": "fef50552-3b78-4e38-bec7-d0cf24e87d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr),moms=(0.8,0.9))"
      ],
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.232635</td>\n",
              "      <td>0.214913</td>\n",
              "      <td>0.905303</td>\n",
              "      <td>0.094697</td>\n",
              "      <td>02:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hVRd7A8e+kV9ILkEBCk4QOoSOCgAIq2AV1FXXFhl33Rd21ve6uq6+uZW2guIoozYYKoiiIKCChhYSWEAJJSAfS282d9497iSGk3JAbbnL8fZ4nD/ecM+ecmRyeX+bOzJlRWmuEEEJ0fE6OzoAQQgj7kIAuhBAGIQFdCCEMQgK6EEIYhAR0IYQwCBdH3djN208PjOntqNsLIUSHtH379nytdUhDxxwW0D0Cw4mPj3fU7YUQokNSSh1p7JjDmlxk+LsQQtiX4wK6o24shBAG5cAauoR0IYSwJ4e1oUs4F0K0VHV1NRkZGVRUVDg6K23Ow8ODiIgIXF1dbT7HcQFdIroQooUyMjLw9fUlKioKpZSjs9NmtNYUFBSQkZFBdHS0zec5sA1dIroQomUqKioICgoydDAHUEoRFBTU4m8ijnuxSOK5EOIsGD2Yn3I25XToKBfpGBVCCPtx6Kv/NWYJ6EKIjuPkyZO8+eabLT5v+vTpnDx5sg1ydDqHBnSTBHQhRAfSWEA3mUxNnrd69Wr8/f3bKlu12l1A33yogIwTZQ7IjRBCNG3+/PkcOnSIwYMHM3z4cM4//3xmzJhBbGwsAJdffjnDhg2jX79+LFiwoPa8qKgo8vPzSUtLIyYmhttvv51+/fpx0UUXUV5ebrf8OWzYIoCpxnzGvns/2cmU2FD+eeVAB+RICNFRPPNVEnuPFdn1mrFdOvHUZf0aPf7888+TmJjIrl272LBhA5dccgmJiYm1QwsXLVpEYGAg5eXlDB8+nKuuuoqgoKDTrpGcnMwnn3zCwoULufbaa/n000+58cYb7ZJ/h9bQq2vOrKGXVFaTVWgZqpN+vIxvE7POdbaEEMImI0aMOG2c+GuvvcagQYMYNWoU6enpJCcnn3FOdHQ0gwcPBmDYsGGkpaXZLT821dCVUlOBVwFn4F2t9fP1js8BXgQyrbv+o7V+t7nrmsyn19C11lRUm8krrgTgLysT2JxawKI5cby5/hAllSaeuqwfo3sGNXQ5IcQfSFM16XPF29u79vOGDRtYt24dmzdvxsvLiwkTJjQ4jtzd3b32s7Ozs12bXJqtoSulnIE3gGlALDBbKRXbQNJlWuvB1p9mgzmAqV4NvdJkCfC51oB+ahjmHYu3cyC7mJJKE/M+3kFOkfFf+xVCtD++vr4UFxc3eKywsJCAgAC8vLzYv38/W7ZsOce5s63JZQSQorVO1VpXAUuBmfa4ef1O0YrqGgAKSipPG9JYXaO5f3Jv/nvLcE6WV7N4c6PTAQshRJsJCgpi7Nix9O/fn0cfffS0Y1OnTsVkMhETE8P8+fMZNWrUOc+fLU0uXYH0OtsZwMgG0l2llBoPHAQe1Fqn10+glJoLzAVwC+91RqdoRbVl26yhoLSSgpIq+ob7ckGfEG4aHYWbixPnhfmyO6Ptx3MKIURDPv744wb3u7u7s2bNmgaPnWonDw4OJjExsXb/I488Yte82atT9CsgSms9EPge+KChRFrrBVrrOK11HJzZKVpuraED5BZVkl9SydDuATw2PQY3F0tWB0b4kZBRKG+ZCiFEPbYE9Ewgss52BL93fgKgtS7QWldaN98Fhtly8/qdohV1Anp2YQXHy6oI9nY7Lc3ACH8Ky6tJP26/jgQhhDACWwL6NqC3UipaKeUGzAJW1U2glOpcZ3MGsM+Wm9dvQ69bQz+QU4zWEOzrflqagRF+ANLsIoQQ9TQb0LXWJmAesBZLoF6utU5SSj2rlJphTXafUipJKbUbuA+YY8vN649yqVtD35dleWEg2Of0gN4nzBc3Zyd+3J8rzS5CCFGHTePQtdargdX19j1Z5/NjwGMtvfmZnaLNB3Q3Fyf+NLo77206TK9QH+6Z2KultxVCCENy7JuiZwxbtAR4peBQXikAwT5uZ5z3xPQYpvUP57UfkskpqiA5p5gHl+2isLy67TMthBDtlIOnzz29hl5eZamhD4z4fVayoHo1dAAnJ8Vj02IwmTVvrE9hxfYMPt+ZyV0fbefh5bv5Lim7bTMuhBA28PHxAeDYsWNcffXVDaaZMGEC8fHxdrlfu5rLpcJkCeg3jepeu6+TR8OtQt2CvLhiSFdWxGewbl8O3m7O/HqogK8SjjF38XYWb5GXj4QQ7UOXLl1YuXJlm9/HsdPn1h+Hbq2hT4oJrd3X1DJMs4ZHUl5dQ2peKXde0JPvHhxPwlMXMTDCjyUS0IUQdjZ//nzeeOON2u2nn36a5557jkmTJjF06FAGDBjAl19+ecZ5aWlp9O/fH4Dy8nJmzZpFTEwMV1xxhYGmz63X5HJqLhdPN2fenzOc3OKm52wZ1j2AqCAv0grKGNMrmD5hvgBcPSyCJ79MYl9WETGdO7VN5m2gteadjalcMqAzkYFeDsuHEIa0Zj5k77HvNcMHwLTnGz183XXX8cADD3DPPfcAsHz5ctauXct9991Hp06dyM/PZ9SoUcyYMaPRyuhbb72Fl5cX+/btIyEhgaFDh9ot++2qhl5RXYNS4ObsxMS+oVw3vFuT5yulmDMmiu5BXgyyjk8HuHRgF1ycFEt/O9om+bZVbnElz6/Zzwe/pjk0H0II+xgyZAi5ubkcO3aM3bt3ExAQQHh4OI8//jgDBw5k8uTJZGZmkpOT0+g1Nm7cWDv/+cCBAxk40H5rP7SrGnp5VQ2ers4tWu16ztho5oyNPm1foLcb18RF8NHWo1wTF0n/rn6NnN22Ts0KufXw8RadZzZrqmrMeLg6t0W2hDCGJmrSbemaa65h5cqVZGdnc91117FkyRLy8vLYvn07rq6uREVFNTht7rnQ7jpF7RXE5k+LIcjbjYeW7+JoQRkJDnizNKfIMhtC0rFCiitsG1K5KTmfSS//xAUvrqfSVNP8CUKIc+q6665j6dKlrFy5kmuuuYbCwkJCQ0NxdXVl/fr1HDnSdP/d+PHjayf4SkxMJCEhwW55c3CTS/0auhlPOwV0P09XXr52MCm5JYx/cT1XvPkr2YXn9q/mqT4As4btR040m76sysSDy3dxoqyKnKJKfk0paOssCiFaqF+/fhQXF9O1a1c6d+7MDTfcQHx8PAMGDODDDz+kb9++TZ5/1113UVJSQkxMDE8++STDhtk09ZVNHNzkcmYN3d3Vfn9jxvUO5tmZ/fnpYB7f781h1e5M5o7vabfrNyenqBKlwFkpNhzIY8J5oU2mX7TpMHnFlXx8+0ju+HA7axKzmNi36XMaUmUy4+ykcHayvelKCGG7PXt+74wNDg5m8+bNDaYrKSkBLItEn5o219PTk6VLl7ZJvhxbQ68f0Ktq8HCxb7vxjaO6s/CmOAZH+vPZjszmT7Cj3KIKgrzdmTm4K0u2HiElt6TRtJkny3lzwyGmxIYxpmcwF8aE8v3eHKpMZy6k3Zy5i+OZ8Z9NlFaaWpN9IUQH066aXCpMNXi6tU1H4MzBXdifXczh/NJG05jNmlw7Lm+XW1xJWCd35k/ri4erM6+sO9ho2ue+3otZa5681LK631VDIzhRVs17mw636J4puSVsOJBH0rEi/udT+7XNCSHav3bVKVpeVYOHHZtc6hrTMxiAHfXasksrTVSZzFRU13D3kh2Mfv5HDuY0vGZgS+UUVRDq606IrztTYsLYklrQ4AyRNWbND/tymTW8W+149fF9QpgSG8arPxxssmZf37JtR3FxUtwyNoqvE7L4NlGmQRDG8keZZfVsyungJpczl6CzV6dofb1CffBxd2FnuiWga62Z9/EO+j+9lts+2MaCjal8m5SNWWtWbs/g4eW72Xm0+Y7MpuQUVRLWyQOAYVEB5JdUcaSg7Ix0x06WU1VjJqaz72n7n5nRDx93F+a8/xtf7MysbUJ5Zd1B7l6y/bQHrrXm+TX7eW/TYS7uF87j02PoG+7L06uSKKuSphdhDB4eHhQUNFwxMhKtNQUFBXh4eLToPId1iioaXiTavY0CurOTYlCkHzuPWoYv/rg/l68TsogK8uKXlHyyCisY0s0fFyfFwp9T0Rq2Hi7g2wfG4+Pe8l+TqcZMQWklodaAHtc9EID4IyeICvY+LW2qtRkoOtjntP1d/D1ZNGc4Ny/6jQeW7aJXqA/3XtiL139Mocas2XH0BMOs192ZfpK3fzrEFUO68vSMfrg6O/Hc5f25+u3NLNx4mPsn925xGYRobyIiIsjIyCAvL8/RWWlzHh4eREREtOgcxwV0pRp8U7StaugAQyIDeOunQ5RVmXjpu4NEBXnxr6sGct2CLaTklnD/pN74eriwLe0E/bp0Yl9WEX//Zh+PXNSHGq0J9W3+r2V+SSWr92TRLdALrSGsk2W2yN6hPnTycGH7keNcPSyCXeknmb1gC04KLowJAyC6XqAHy8yT256YzKaUfB5ctov7l+7C38sVs1nz3qbDtQH9/V/S8PVw4bnL++Nt/QMUFxXI9AHhvLPxEDeM6nbG3PJCdDSurq5ER0c3n/APyrE19DM6Rc1t1oYOMKSbPzVmzdqkbPZmFfG3S2OJiwrE38uVk2XVjO8TQmSgJz8dzOOZGf1YFp/OOz+lsmpXJtEh3nx97/nN3uOTrUd56fvfOz97hVhq3U5OiuFRgXyTkMXlg7uybFs6Lk6KarOZr3Yfw8fdpcG53wFcnJ2YcF4oGx6dyI/7c+gW6MV3e3NYuDGVjBNluDg5sWZPFnPGRNUG81Mevug8Vu/JZvHmIzw4pU8rfntCiPbOYW3oSp25wEV5GwxbrCuueyBKwYKNh63bATg7KSaeF0qQtxuDIvwI9fVg8W0j6RHiw4OT+zCgqx+uLk4kZhbZNAImJa+EUF93Xp01mA2PTGBkj6DaY09eFkuwjzt/WvQb3+zJYsbgLoy2Ho8O9m52ygM/T1euGBLBsO6B3Dw6CqUUH/yaxkdbjlCjNTePiTrjnJ4hPkyOCWXxliOnrQglhDAexwV0FDU1p3fqteWwRQA/L1f6hluaUtxcnGpnYnz6sn58fvdYXJxP/3V4uDqzat5YPrptJAA/J+c3e49DeSWcF+7LzMFdz2gr7x7kzad3jSE6yJtKk5lr4yJrXxxqqLmlKV38PZk+oDOf/JbO4i1HmBwT1uiMjreOjeZ4aRVrZeEPIQzNcaNcFFTXGeVSaTKjNW0+IdWoHpY2535dOuHmYim+n5cr3YIaDoZKKWI7dyLI241NKfmYasxsOJB7RnMRWP4oHc4rpWeITwNXsgjwdmPp3FF8cOsIBkX6M6GPJaD3CGlZQAd4aEofooO9KaqoZu74Ho2mG9UjiFBfdxnCKITBObgN/fcaekFpFQABXg23I9vLyOgg3v8ljcGR/s0ntnJyUoztFczPyfl8uiOD//l0D8OjAnhvznC0Bh93F5ydFDlFlZRW1dCzmeAc4O3GBX1CAMvKSwtvimNY94AWlyU62Juv7h1HSaWpyZE4Tk6Kqf3DWR6fTlmVCS83h874IIRoIw5tQ687Dv3UxFmd/Vo27rKlRvcMomeINxfFhrfovPN7B5NfUsn7v6Th7ebMtrQTLN58hEkvbeDKN38hr7iSQ3mWF4CaqqE3ZEpsGIHeZ/+HzJZhldP6d6ai2swP+3J59+dU1u1tfL5mIUTH5MAa+unDFk8F9PA2Duh+nq788PCEFp93fm9LjXp/djEzBnUhObeE139MpqLazImyap5elVTbnNOjhQH9XBgRHUhEgCf/XneQw/mlhPl6ML5PSG2zkxCi43NwDf33gJ5VaFlXL7xT2wb0sxXu50GvUEugHt0ziEsGhFNRbaarvyczB3dhS2oB+7KL8XF3qR173p44OyluHh1Fap7lJabsogq+2XPMwbkSQtiTg+dy+b3JJaeoAncXJ/y9XB2Yo6ad39syH8zoHkFMH9AZgKuGdiWueyAFpVV8tesYo3oEtmjFpXPp2rhIOnm4cPv5Pegd6sOL3x7g2En7LVArhHAshzW5OKnTO0WzCivo7OfRboMhwB3jexLbuVPtcMRP7xpDvy6daudnKa40cUEzc547kp+XKz//5UJ8PFyYMagLsxds4c8fxPPNfePa9e9dCGEbB9bQFTXm09vQw9ppc8sp4X4eXBMXWbs9rHsAHq7O9A71wdfaMTnBOnqlvfLzcsXZSdG/qx/zp/dlb1YRSceKHJ0tIYQdOPhN0TqjXIoq2nyES1txclKM7BHIeWG+jb7c0x5N798ZZyfFWz8d4qXvDsibpEJ0cO1iHLrZrMkpqiDcz9NR2Wm1F68edNofqI4gwNuNsb2C+SYhC7CMa79yaMtmdxNCtB8OrKGr2k7RgtIqqms04e1wdIitArzdbJqNsb2564KeTI4JJTLQk6W/pTs6O0KIVmgXwxZziy1j0Nt7G7oRje4ZxLs3D+f6Ed35Le04//kxWdYiFaKDsimgK6WmKqUOKKVSlFLzm0h3lVJKK6Ximr0m1HaKFpRYXvsPkvm6Heb6Ed0Y0zOI//vuIHcs3s5fv9jDwo2phl8ZRggjabYNXSnlDLwBTAEygG1KqVVa67310vkC9wNbbbqz+n0c+nHrPC6tef1dtI6flysf3z6K5fHp/GVlAptSLPtTckv4x5UDcHaSYY1CtHe2dIqOAFK01qkASqmlwExgb710/wv8C3jUlhvXffX/1MRcQRLQHe7auEhCfNyJDPTiy12ZvP5jCq4uiucuH+DorAkhmmFLk0tXoG5vWYZ1Xy2l1FAgUmv9TVMXUkrNVUrFK6XiKysqaifnOl5aibOTws+z/b4l+kcysW8ovUJ9ePii85gzJoqPthwl1TrxmBCi/Wp1p6hSygl4GXi4ubRa6wVa6zitdZynp0dtp+jx0ioCvNxwkq/17c49E3vh6qxYvOWIo7MihGiGLQE9E4issx1h3XeKL9Af2KCUSgNGAaua6xhVSlFRXUONWVNQUiXNLe1UiK87lwzozMr4DA5kF/Poit0ctU51IIRoX2wJ6NuA3kqpaKWUGzALWHXqoNa6UGsdrLWO0lpHAVuAGVrr+KYu6uXmTEW1mV9S8jleWiUdou3Y3RN7UV5dw8w3NrFiewaPf75HRr8I0Q41G9C11iZgHrAW2Acs11onKaWeVUrNONsbd/Jwxd/LlWXx6ZaA3siK98Lx+oT5ctu4aCqqzYzqEcimlHzWyHJ2QrQ7NrWha61Xa637aK17aq3/bt33pNZ6VQNpJzRXOwfLi0WXD+7K90k5pBWUSpNLO/fIxeex4s7RfHTbSHqF+vDqumTMZvvX0r/afYzR//yBn5Pz7H5tIYzOofOhT+0fTlWNGbOWMejtnauzE8OjAnFxdmLexF4cyCnmOzsvY1dUUc0zXyWRVVjBLe9vIzGz0K7XF8LoHBrQh3T7faFmqaF3HJcO7ExUkBev/5hst7b0SlMNf1mRQEFpFR/dNhIvN2de/v4gr/2QTEquDJkUwhYODejuLs61S84Festr/x2Fi7MTd0/sRdKxItYfyLXLNV/89gDfJmXz10tiGdc7mDljovhxfy4vf3+QZ75Ksss9hDA6h68QPCjSDwAXZxmD3pFcMaQrXf09effnw3a53s70k4yIDuS2cdEA3DoumimxYVwUG8bPyfnsy5JFOIRojsMD+v9e3p9rhkXUrtcpOgZXZyeujYtkc2oBmXZYl/To8TKign5fHMTfy42FN8XxwtUD8XJzZuHPqa2+hxBG5/CAHurrwYvXDMLLzWFrbYizdMWQrmgNX+zMbD5xE8qrasgrrqR7kPcZx/y93Lg2LpJVu46RVSgLWgvRFIcHdNFxdQvyYnhUAB9vPdqq5evST1jePG1s+b7bxkVj1pr37NS8I4RRSUAXrfLg5D5knizn6VVJtUvZtdQR61QC3RoJ6JGBXlw5NIL3f01jW9rxs86rEEYnAV20yphewUwfEM7Sbenc8/EONh8qsPncGrPm1XXJLNtmmcyzsYAO8NRlsUQGePLw8t2Yas5u7dY31qfw5a7WNQ8J0Z5JQBet9tI1g/n63nGE+rrzyrqDDaZZm5TNPUt21DbNaK15/LM9/HvdQdbty8HFSRHg1fj0yb4ersyfFsPR42WsTWr5C01p+aW8uPYAj6zYLS8sCcOSgC5azdPNmf5d/bh7Qk+2Hj7OJ78dPSPN5zsy+WZPFn9ZmYDWmp3pJ1kWn87kmDDAsr6sUk0PXZ0SG0ZUkBfvbDxUu3yhrRZvOWL9o+HGIyt2n3F+RXUNt/13W6s7eIVwJAnowm5uHNWdC/qE8NcvEtl59MRpx5KyCvF2c2bV7mNsTM7nv7+k4evuwquzBnP9yG48PKVPs9d3dlLcN6k3CRmFPL0q6bS3VCuqaxp9a7WiuoYV8elM7R/O3y6NZX92MZ/XC9wvrj3AD/tz+duXiRSUVJ5F6YVwPBkrKOzGxdmJN24YyoQX1/Py9wdZfNtIAArLq0k/Xs79k3qzIj6dZ1YlcfR4GTeNjsLb3YV/XGH78nZXDo3gQHYx72xMJS4qgDE9g7l7yXbij5xgWLcAFtwUR6C3GyWVJj7fkUF+SRVd/T0pqjAxa7hlIeyFP6fy92/24qTA09UZP09XFv1ymMkxYaw/kMutH8Rzy5goRvcMIsz6JrMQHYEEdGFXPu4u3H5+D/65Zj8bDuQy4bzQ2rc8B3fzJ9zPg8c+28OgSH/unNDjrO7xl6l92ZZ2nL9+nkgnT1eOl1Zxy5holmw9wvULt/DhrSO4e8kO4o9YviW4OCnCOrkzumcQTk6KV64bzJ8/jOeh5bsBcFIQGeDFq7MGszYpmxe+PcADy3bh4+7C0rmj6N/Vzz6/HCHamHLUQgVxcXE6Pr7ZWXZFB1RaaeLS1zdxpKCUF68exMnyav7367389sQkQnzc2ZdVTN9w31YtOXikoJS/fpFIZbWZB6f0YXTPIDYezOOW/26rbXp5bfYQUnJLeGVdMnPH9+Dx6TGn5XFvVhGH80t5+6dDvHDVQOKiAgEw1ZhJOlbEXR9tp6rGzIe3jiS2S6fW/VKEsBOl1HatdYMrwklAF22ipNLETe9tJf1EOX3DfdmfXcy2Jya3+X1Xbs9g86ECbhzVjSHdAjDVmHn/lzRmDulCqG/Lmk8O5ZVw47tbKakw8fV94xp8k1WIc00CunCILakFzFqwBYBHLurDvAt7OzhHLZd+vIypr2xkdM8g3r15uKOzI0STAV1GuYg2M6pHEDMGdeG6uEjuntDL0dk5K5GBXtw7qTfr9uXabapgIdqK1NCFaEaVyczUVzaigW8fOB93F2dHZ0n8gUkNXYhWcHNx4qkZ/TicX8qiTWmOzo4QjZKALoQNLugTwpTYMF7/MZnswgpHZ0eIBklAF8JGT14ai8ms+cunCS2eekCIc0ECuhA2igz04qnLYtl4MI///Jhit+t+uSuTmf/ZxMGcYrtdU/wxSUAXogWuH9GNGYO68Mb6FFbEp/PZjoxWX/Or3cfYnVHIlW/+KiNpRKtIQBeiBZRS/PXSGNxdnHh0ZQIPLd/N2qTss76e1prdGYWc3zuY7kFeDc74uGzbUZ78MpGyKlNrsy8MTgK6EC0U6uvB69cP4ZkZ/ejftRPzP00gt+jsOkqziyrIK65kUt9QVtw5mhHRgTy8Yjdr9lhWf/o1JZ/HPtvDh5uPMHvBFqrPcnEP8ccgAV2IszDhvFBuHhPFK9cNoby6hkdWJmA+i47S3emWxTYGRvrj5ebCezcPZ3CkP/d+spMPfk3j3k920iPEh39cMYDdGYWsiG99E09r/Jycx5NfJvLepsMyzXA7JAFdiFboFerDE9Nj2Hgwjw83p3G0oKxFI2ASMk7i4qSI7WyZ/Mvb3YX3bxnOkG7+PLUqiYrqGt6+cSizR0QS1z2Af687yK70k7XnF5RUtmqB7pZIyS3mzx/Es2xbOv/79V6GPbeOaa/+TFZh+Tm5v2ieBHQhWunGUd2ZeF4Iz3y9l/EvrueJz/fYdJ7ZrPk2MZtBkf54uP7+9mknD1c+vn0Uj158Hu/8KY5eob4opXjqsn5orbnizV/4NjGbdXtzGPev9cz7eEdbFe20vD60fDc+7i78/D8T+f7B8Tw8pQ+Hckt46buGlx0U557Mhy5EKymleOHqQTz9VRJVJjNLt6VTY9bcMja60Wl3K6prWJuUTWp+Ka83sFqTq7MT90w8ff6bARF+bHh0Ijcs3MJ9S3dSZTLTycOFdftyiU87Xjv9b1tYuSODhIxCXp01mFBfD0J9Pegd5ktxpYmFP6cyZ0yUzBvfDkgNXQg7CPF1543rh/LWDUO5cmhXvk7I4ub3f6OwrPqMtGaz5uJXNnL/0l1EBHgyrX+4zffxcXfh9dlD6RHszd0TerLh0YmE+LrzyIrdJB2z/+LXlaYaHlq2i799kciQbv7MGNTltOP3TOhFkLcbj322B1MTHbbnqlnoj86mgK6UmqqUOqCUSlFKzW/g+J1KqT1KqV1KqU1KqVj7Z1WI9s/F2YmXrx3MijtHc7y0ise/2HPGyJSd6Sc5UlDG7BHdePvGYbg4t6xe1S3Ii28fGM9fpvYl0NuNN28YSnl1DVe99SvfJp79EEqw/LGpG3zf3pDKZzszuXJoV16fPeSMhbz9vFx5ekY/9mQWsuiXw7X7U/NK+GFfDgCJmYUMfvY73vnpUKvyJprX7GyLSiln4CAwBcgAtgGztdZ766TppLUusn6eAdyttZ7a1HVltkVhdG9uSOGFbw8wIjqQm0dHcTi/hIv6hfPp9gwW/XKY7X+bQicPV7vcK7+kkts/jGdX+kkem9aX28/vcUbwbU5qXgnzPt7J8dIq/nnlAF5ce4CDOcVMH9CZ12YPafQ8rTW3f7idTSl5jOsVgllrtqUdp7jCxAe3jmDx5iOs25eDUvD2jcO4uJ/t30jEmVq1wIVSajTwtNb6Yuv2YwBa6382kn42cJPWelpT15WALv4IPtuRwTNf7aWw/PemFzcXJ0b1COLDW0fY9V4V1TU8vHw33+zJ4qLYMF6ZNRgvN/t2EhkAABAhSURBVNu7yW54dwuJmUWUVpowmTVd/Dy4uH84913YmwBvtybPzS6s4KJ//4SLsxNebs4EebtRWlVD5olyyqtruGdiTzYl55OcW8KKO0fTr4ulvb3KZMbNRVp+W6K1Af1qYKrW+s/W7T8BI7XW8+qluwd4CHADLtRaJzdwrbnAXIBu3boNO3LkyFkUR4iOpbCsmqRjhUSHePPZjkw+3ZHB/Kl9uagNaqpms+a9TYf5++p93DepNw810OHakBqzZuDTa7l6WATBPu4s/DmVZXeMJqaz7WupFpRU4uXmgqebZcTOobwS3vnpEG4uTsyfFkNZpYkZ//kFJwVf3DOWF9YeYMOBXJbfMZoeIT5UVNecNtpHNOycBPQ66a8HLtZa39zUdaWGLkTbuWfJDtYfyGXDIxMI7dT8WqoHsou5+JWNvHztIK4cGtFmNefEzEKueXszNWZNVY3lHl39Pfn75f259YNt3HlBTx6YbNsfoT+q1i5wkQlE1tmOsO5rzFLgctuzJ4Swt0cvPo8qk5lXfjjji3KDdltfVhoU6Q/QZs0g/bv6seyOUcwaEckDk3vz0W0jOXq8jJsW/Ualycwr65IZ/8J63pYO1LNiSwPbNqC3UioaSyCfBVxfN4FSqnedJpZLANv+Fwkh2kRUsDc3jOzGR1uPcv2Ibs2OEd+VcRJfDxeig7zbPG8DI/wZGOFfu33vhb14ZV0y/7xyADlFFWw+VMDza/bj7e7Cn0Z1b/P8GEmzAV1rbVJKzQPWAs7AIq11klLqWSBea70KmKeUmgxUAyeAJptbhBBt795Jvfli1zEu+88mRkYHcsPI7lxWbxy52axZsT2dNXuyGBThj5NTy0bG2MN9F/bm4n7h9A23vBE7b6KZ2z6I5x/f7GNKTBjhfs03GQkLWSRaCAPLLqzgk9+O8lXCMVLzSukW6EV+SSVjewWTeaIck9nMwZwSBkf68/cr+teOPnG09ONlTHr5J8b1Cub/rhlEYDOjbP5IWtUp2lYkoAtx7phqzPx73UF2Hj1JiK878Wkn6BHiTXlVDVcOjWD2iMgWj1tva+/+nMo/Vu/D292Fpy7rx1VDu7a7PDqCBHQhRIeUklvM458l8lvacS7sG8ozM/qxObWAniHeDOvednPXtGcS0IUQHZbZrPnvr2m8sHY/FdW/T6Mwvk8IMwd1YXA3f3qG+Dgwh+dWUwFdZlsUQrRrTk6KW8dFM7FvKG9tSGFKbDipeSW8/dMhNh7Mw8vNmR8fniCdp0gNXQjRQZVX1bA3q5DZC7cyvncwF/cLZ/WeLAZF+nPruGi7zZPT3kgNXQhhOJ5uzgzrHsj9k3rz4toDrNuXS1gndzYczGPjwTwuGdiFUF93pvYPx7WFM1p2VBLQhRAd2j0Te3HJgM7kFFUwPCqQ7/Zmc/eSHew4ann7NayTO3dd0JM5Y6ObvI7WusOPopEmFyGE4ezPLsLH3YXk3BIW/JTK5tQCxvQM4lBeCRf3CyciwJPLBnWhs58nZrNm/mcJJGQU8tndY1o0Q6UjyCgXIcQfltmseWDZLr7Zk8WoHoFsST1OjVkT6O3Gq7MGszYpm4+2HAXgjgt68Ni0GAfnuGkS0IUQf2haa06WVRPg7UalqYYjBWXcs2QHybklgCWQnyytZuWODBbNGc4FfUIcnOPGSaeoEOIPTSlVu0iHu4szfcJ8+eKesTy/Zj/dAr348/nRlFbVkJBZyB2L4xnVI4gu/p7cOb4n3YK8bLrH+gO57Mko5OphEXTx92zL4jRKauhCCGGVU1TBy98dZHfGSdIKSuke6M2X88bWLrxRaaohMbOIwZH+OFsnMkvJLcbdxZmZb/zC8dIqfNxd+Pj2kafNKGlPrZ0PXQgh/hDCOnnwr6sH8u0D43n7xmEcyCnmwWW7qDJZ3lD95+r9XPXWr0x6aQOZJ8spta7CNPH/NnC8tIrXZg/B38uVOe9vI8XanHMuSUAXQogGTDgvlL9dGsuaxGzu+2QnafmlLNl6hPF9QsgpquTJLxJZty+HsqoaArzduHRgZ2YM6sJHt43ESSluem8r+SWV5zTP0uQihBBNePfnVJ77Zh+ers5oND89OpFVu47x99X7COvkDsCv8yehoHY++cTMQq5881dG9QyisKwKs4a543vUzkffmjHv0ikqhBBn6bZx0eQUVZCcW8IDk/sQ1smDW8ZGsTvjJF8nZDFnTFRte/op/bv6cffEnryyLplQX3cCvd14YNkuvN2d2Z1eyJe7Mvng1hF0t/MKUVJDF0KIs1Bj1ny1+xgTzgvB3+vMBTgqTTUs2XKUaQPC8fVw5bp3NnMguxiTWaMUBPu4M2NQFx6c0gcfd9vr1jIOXQghHKyoopr7P9nJibJqnrwsllfWJfNLSj4X9Alh4U1xZ9TyGyMBXQgh2om67ecfbTnCX79I5KEpfbhvUm+bzpdhi0II0U7U7Qy9cVR3Zgzqwms/JLMno7DJ82ypfEtAF0IIB3p2Zj9CfN2Zuzie9ONlaK3JLqzg2MlyCkoqWbgxlfySSmYt2MKXuzKbvJaMchFCCAfy93Lj3ZvjuPbtzVzw4no8XZ0prapBKfDzdOVkWTWv/ZhMcYWJW5qZAlgCuhBCOFi/Ln6svv98Pt2eQVGFiR4h3mQXVrA5tYALzwvl3+sOct+FvZjaP7zJ60inqBBCtHOF5dX4eVqW1JNOUSGE6MBOBfPmSEAXQgiDkIAuhBAGIQFdCCEMQgK6EEIYhAR0IYQwCAnoQghhEDYFdKXUVKXUAaVUilJqfgPHH1JK7VVKJSilflBKdbd/VoUQQjSl2YCulHIG3gCmAbHAbKVUbL1kO4E4rfVAYCXwgr0zKoQQomm21NBHACla61StdRWwFJhZN4HWer3Wusy6uQWIsG82hRBCNMeWgN4VSK+znWHd15jbgDUNHVBKzVVKxSul4vPy8mzPpRBCiGbZtVNUKXUjEAe82NBxrfUCrXWc1jouJCTEnrcWQog/PFtmW8wEIutsR1j3nUYpNRl4ArhAa11pn+wJIYSwlS019G1Ab6VUtFLKDZgFrKqbQCk1BHgHmKG1zrV/NoUQQjSn2YCutTYB84C1wD5gudY6SSn1rFJqhjXZi4APsEIptUsptaqRywkhhGgjNi1wobVeDayut+/JOp8n2zlfQgghWkjeFBVCCIOQgC6EEAYhAV0IIQxCAroQQhiEBHQhhDAICehCCGEQEtCFEMIgJKALIYRBSEAXQgiDkIAuhBAGIQFdCCEMQgK6EEIYhAR0IYQwCAnoQghhEBLQhRDCICSgCyGEQUhAF0IIg5CALoQQBiEBXQghDEICuhBCGIQEdCGEMAgJ6EIIYRAS0IUQwiAkoAshhEFIQBdCCIOQgC6EEAYhAV0IIQxCAroQQhiEBHQhhDAICehCCGEQEtCFEMIgbAroSqmpSqkDSqkUpdT8Bo6PV0rtUEqZlFJX2z+bQgghmtNsQFdKOQNvANOAWGC2Uiq2XrKjwBzgY3tnUAghhG1cbEgzAkjRWqcCKKWWAjOBvacSaK3TrMfMbZBHIYQQNrClyaUrkF5nO8O6r8WUUnOVUvFKqfi8vLyzuYQQQohGnNNOUa31Aq11nNY6LiQk5FzeWgghDM+WgJ4JRNbZjrDuE0II0Y7YEtC3Ab2VUtFKKTdgFrCqbbMlhBCipZoN6FprEzAPWAvsA5ZrrZOUUs8qpWYAKKWGK6UygGuAd5RSSW2ZaSGEEGeyZZQLWuvVwOp6+56s83kblqYYIYQQDiJvigohhEFIQBdCCIOQgC6EEAYhAV0IIQxCAroQQhiEBHQhhDAICehCCGEQEtCFEMIgJKALIYRBSEAXQgiDkIAuhBAGIQFdCCEMQgK6EEIYhAR0IYQwCAnoQghhEBLQhRDCICSgCyGEQUhAF0IIg5CALoQQBiEBXQghDEICuhBCGIQEdCGEMAgJ6EIIYRAS0IUQwiAkoAshhEFIQBdCCIOQgC6EEAYhAV0IIQxCAroQQhiEBHQhhDAICehCCGEQNgV0pdRUpdQBpVSKUmp+A8fdlVLLrMe3KqWi7J1RIYQQTWs2oCulnIE3gGlALDBbKRVbL9ltwAmtdS/g38C/7J1RIYQQTbOlhj4CSNFap2qtq4ClwMx6aWYCH1g/rwQmKaWU/bIphBCiOS42pOkKpNfZzgBGNpZGa21SShUCQUB+3URKqbnAXOtmpVIq8Wwy3UEEU6/8BmT0Mhq9fGD8MhqxfN0bO2BLQLcbrfUCYAGAUipeax13Lu9/Lhm9fGD8Mhq9fGD8Mhq9fPXZ0uSSCUTW2Y6w7mswjVLKBfADCuyRQSGEELaxJaBvA3orpaKVUm7ALGBVvTSrgJutn68GftRaa/tlUwghRHOabXKxtonPA9YCzsAirXWSUupZIF5rvQp4D1islEoBjmMJ+s1Z0Ip8dwRGLx8Yv4xGLx8Yv4xGL99plFSkhRDCGORNUSGEMAgJ6EIIYRAOCejNTSXQESml0pRSe5RSu5RS8dZ9gUqp75VSydZ/AxydT1sppRYppXLrvivQWHmUxWvW55mglBrquJzbrpEyPq2UyrQ+x11Kqel1jj1mLeMBpdTFjsm17ZRSkUqp9UqpvUqpJKXU/db9hniOTZTPMM+wxbTW5/QHS8fqIaAH4AbsBmLPdT7aoFxpQHC9fS8A862f5wP/cnQ+W1Ce8cBQILG58gDTgTWAAkYBWx2d/1aU8WngkQbSxlr/r7oD0db/w86OLkMz5esMDLV+9gUOWsthiOfYRPkM8wxb+uOIGrotUwkYRd0pET4ALndgXlpEa70Ry4iluhorz0zgQ22xBfBXSnU+Nzk9e42UsTEzgaVa60qt9WEgBcv/5XZLa52ltd5h/VwM7MPyVrchnmMT5WtMh3uGLeWIgN7QVAJNPYSOQgPfKaW2W6c4AAjTWmdZP2cDYY7Jmt00Vh6jPdN51iaHRXWayTp0Ga0zoA4BtmLA51ivfGDAZ2gL6RS1n3Fa66FYZqW8Ryk1vu5BbfnOZ5gxokYrTx1vAT2BwUAW8JJjs9N6Sikf4FPgAa11Ud1jRniODZTPcM/QVo4I6LZMJdDhaK0zrf/mAp9j+SqXc+orq/XfXMfl0C4aK49hnqnWOkdrXaO1NgML+f0reYcso1LKFUuwW6K1/sy62zDPsaHyGe0ZtoQjArotUwl0KEopb6WU76nPwEVAIqdPiXAz8KVjcmg3jZVnFXCTdZTEKKCwzlf6DqVem/EVWJ4jWMo4S1kWc4kGegO/nev8tYR1Cuv3gH1a65frHDLEc2ysfEZ6hi3miJ5YLL3pB7H0Mj/h6J5hO5SnB5be891A0qkyYZlC+AcgGVgHBDo6ry0o0ydYvq5WY2lrvK2x8mAZFfGG9XnuAeIcnf9WlHGxtQwJWAJA5zrpn7CW8QAwzdH5t6F847A0pyQAu6w/043yHJson2GeYUt/5NV/IYQwCOkUFUIIg5CALoQQBiEBXQghDEICuhBCGIQEdCGEMAgJ6EIIYRAS0IUQwiD+H0vLGWH2ERv1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxGAYja9i_e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('second_cycle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLzbqXbBjB2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('second_cycle');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5Un9JlHjFHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfyKhP-ljGdE",
        "colab_type": "code",
        "outputId": "22379355-9ddc-4738-f40c-6ab446612865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "learner.fit_one_cycle(1, max_lr=slice(lr*0.95**num_groups, lr),moms=(0.8,0.9))"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.182978</td>\n",
              "      <td>0.212460</td>\n",
              "      <td>0.910985</td>\n",
              "      <td>0.089015</td>\n",
              "      <td>02:49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCO8JUEnjI8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.save('third_cycle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOFbejCQjPP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_all(seed)\n",
        "learner.load('third_cycle');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxCbnyhVtB66",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Here, I unfreeze all the groups.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKRl7AyyjQtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJw_63IcjSPy",
        "colab_type": "code",
        "outputId": "46d03ae0-7109-4c0a-99ec-c5492ad140df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "learner.fit_one_cycle(2, max_lr=slice(lr*0.95**num_groups, lr),moms=(0.8,0.9))"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.255679</td>\n",
              "      <td>0.236354</td>\n",
              "      <td>0.888258</td>\n",
              "      <td>0.111742</td>\n",
              "      <td>04:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.159158</td>\n",
              "      <td>0.215915</td>\n",
              "      <td>0.903409</td>\n",
              "      <td>0.096591</td>\n",
              "      <td>03:59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zQYsEKUujl8",
        "colab_type": "text"
      },
      "source": [
        "***Prediction:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui2-cmP2TZo2",
        "colab_type": "text"
      },
      "source": [
        "Try an example of the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu41HvnRjTaC",
        "colab_type": "code",
        "outputId": "05d62dc1-02af-4318-a81b-a912253e6634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "learner.predict('How Boris Johnson s cheery wounded in action persona may save him yet again Let s hope not Johnso')"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(1), tensor(1), tensor([0.0017, 0.9983]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M1sBQe2ThCd",
        "colab_type": "text"
      },
      "source": [
        "Make all the predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltqKBFR3kMkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction=[]\n",
        "for i in test.text:\n",
        "  p=learner.predict(i)\n",
        "  sample_prediction=p[2][1].tolist()\n",
        "  prediction.append(sample_prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0y2pnB-lx70",
        "colab_type": "code",
        "outputId": "5671f585-abda-4f03-bdc3-2f660a34e5d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(prediction)"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1962"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaKlHdbG6rZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "0597f211-79da-4c8d-f104-3361ba3c5c71"
      },
      "source": [
        "prediction[0:5]"
      ],
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9931851029396057,\n",
              " 2.886372385546565e-05,\n",
              " 2.3880702428868972e-05,\n",
              " 0.9983425140380859,\n",
              " 1.2061724191880785e-05]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 379
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wawq0x3zvc7V",
        "colab_type": "text"
      },
      "source": [
        "## **Roberta Large Model2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kq9GB4mL524-",
        "colab_type": "text"
      },
      "source": [
        "In this part, I use another notebook because i tried the batchsize 32 so if you face an error  (Cuda out of memory) please run this code separently and don't forget to import the Libraires in the beginning of the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwd3Xhfogma_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_PATH = '/content/updated_train.csv'\n",
        "TEST_PATH = '/content/updated_test.csv'\n",
        "SAMPLE_SUB_PATH = '/content/updated_ss.csv'\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "sample_sub = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "ID_COL, TARGET_COL = sample_sub.columns.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsN_rWL_wNyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train1=train.drop(['ID'],axis=1)\n",
        "testt=test.drop(['ID'],axis=1)\n",
        "testt['label']=0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vyEaOA55Hds",
        "colab_type": "text"
      },
      "source": [
        "Define the parameters of the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALKgmDm7wOQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "argss = {'train_batch_size':32,\n",
        "                                                                         'reprocess_input_data': True,\n",
        "                                                                         'overwrite_output_dir': True,\n",
        "                                                                         'fp16': False,\n",
        "                                                                         'do_lower_case': False,\n",
        "                                                                         'num_train_epochs': 2,\n",
        "                                                                         'max_seq_length': 64,\n",
        "                                                                         'regression': False,\n",
        "                                                                         'manual_seed': 2,\n",
        "                                                                         \"learning_rate\":3e-5,\n",
        "                                                                         'weight_decay':0,\n",
        "                                                                         \"save_eval_checkpoints\": False,\n",
        "                                                                         \"save_model_every_epoch\": False,\n",
        "                                                                         \"silent\": True}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNIZ56ix5zjR",
        "colab_type": "text"
      },
      "source": [
        "train the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhdRowNnwOT5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "a7b16820-9542-452e-ba57-77c6f59a72aa"
      },
      "source": [
        "erreur=[]\n",
        "pred2=[]\n",
        "fold=StratifiedKFold(n_splits=20, shuffle=True, random_state=2)\n",
        "for train_index, test_index in fold.split(train1,train1['target']):\n",
        "    train1_trn, train1_val = train1.iloc[train_index], train1.iloc[test_index]\n",
        "    model = ClassificationModel('roberta', 'roberta-large', use_cuda=True,num_labels=2, args=argss)\n",
        "    model.train_model(train1_trn)\n",
        "    raw_outputs_val = model.eval_model(train1_val)[1]\n",
        "    raw_outputs_val = softmax(raw_outputs_val,axis=1)[:,1]\n",
        "    print(f\"Log_Loss: {log_loss(train1_val['target'], raw_outputs_val)}\")\n",
        "    erreur.append(log_loss(train1_val['target'], raw_outputs_val))\n",
        "    raw_outputs_test = model.eval_model(testt)[1]\n",
        "    raw_outputs_test = softmax(raw_outputs_test,axis=1)[:,1]\n",
        "    pred2.append(raw_outputs_test)\n",
        "prediction_2=np.mean(pred2, 0)\n"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7f2060047258>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\", line 220, in __iter__\n",
            "    self.sp(bar_style='danger')\n",
            "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n",
            "Exception ignored in: <generator object tqdm_notebook.__iter__ at 0x7f205c8c3d00>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\", line 220, in __iter__\n",
            "    self.sp(bar_style='danger')\n",
            "AttributeError: 'tqdm_notebook' object has no attribute 'sp'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-380-bd9ffd1e7685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain1_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain1_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roberta-large'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain1_trn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mraw_outputs_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain1_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mraw_outputs_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0meval_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         )\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, output_dir, multi_label, show_running_loss, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_inputs_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m                 \u001b[0;31m# model outputs are always tuple in pytorch-transformers (see doc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/transformer_models/roberta_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         )\n\u001b[1;32m     69\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         )\n\u001b[1;32m    738\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             )\n\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add cross attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36m_gelu_python\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mAlso\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 11.17 GiB total capacity; 10.09 GiB already allocated; 29.81 MiB free; 702.50 MiB cached)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfYlgnZrMU6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicition2=prediction_2.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-36NWyOnMPCh",
        "colab_type": "text"
      },
      "source": [
        "Final result after running the two models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-25SBMowOXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=[]\n",
        "for i in range(0,len(prediction)):\n",
        "  h=0.75*prediction2[i]+0.25*prediction[i]\n",
        "  result.append(h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av1EWSbtwOZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_sub.target=result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dRlADoWM0UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_sub.to_csv('larabe.csv',index=False)#0.1658"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}